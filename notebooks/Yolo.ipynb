{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov7'...\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/WongKinYiu/yolov7.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abel\\Documents\\10 Academy\\week-10\\Automated-Storyboard-Synthesis-for-Digital-Advertising\\notebooks\\yolov7\n"
     ]
    }
   ],
   "source": [
    "%cd yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.4, device='', exist_ok=False, img_size=1280, iou_thres=0.45, name='run', no_trace=False, nosave=False, project='trial', save_conf=False, save_txt=False, source='/_preview.png', update=False, view_img=False, weights=['yolov7-tiny.pt'])\n",
      "Fusing layers... \n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "Done. (935.8ms) Inference, (11.6ms) NMS\n",
      " The image with the result is saved in: trial\\run3\\_preview.png\n",
      "Done. (1.037s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  2024-2-16 torch 2.2.0+cpu CPU\n",
      "\n",
      "c:\\Users\\Abel\\Documents\\10 Academy\\week-10\\Automated-Storyboard-Synthesis-for-Digital-Advertising\\.venv\\lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 200 layers, 6219709 parameters, 229245 gradients, 13.7 GFLOPS\n"
     ]
    }
   ],
   "source": [
    "! python detect.py --weights yolov7-tiny.pt --conf 0.4 --img-size 1280 --source /_preview.png --project trial --name run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='/as.png', update=False, view_img=False, weights=['yolov7.pt'])\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "1 person, 1 cake, Done. (1668.0ms) Inference, (20.0ms) NMS\n",
      " The image with the result is saved in: runs\\detect\\exp3\\as.png\n",
      "Done. (1.895s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  2024-2-16 torch 2.2.0+cpu CPU\n",
      "\n",
      "c:\\Users\\Abel\\Documents\\10 Academy\\week-10\\Automated-Storyboard-Synthesis-for-Digital-Advertising\\.venv\\lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 306 layers, 36905341 parameters, 6652669 gradients, 104.5 GFLOPS\n"
     ]
    }
   ],
   "source": [
    "! python detect.py --source /as.png --weights yolov7.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import csv\n",
    "\n",
    "# Define the directory you want to start from\n",
    "rootDir = '/Assets'\n",
    "\n",
    "for dirName, subdirList, fileList in os.walk(rootDir):\n",
    "    for fname in fileList:\n",
    "        if fname.endswith('_preview.png'):\n",
    "            # Run the detect.py script\n",
    "            command = f\"python detect.py --source {os.path.join(dirName, fname)} --weights yolov7.pt\"\n",
    "            result = subprocess.run(command, shell=True, stdout=subprocess.PIPE)\n",
    "\n",
    "            # Save the output in a CSV file\n",
    "            with open(f\"{dirName}.csv\", \"w\") as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([result.stdout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
